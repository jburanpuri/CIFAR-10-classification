{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Other imports\n",
    "import operator\n",
    "%matplotlib inline\n",
    "from collections import namedtuple\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from __future__ import print_function, division\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Torch imports\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Alexnet Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting alexnet\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "\n",
    "#Basic transforms using mean and std\n",
    "# Transform variable to convert images to the right size\n",
    "transform = transforms.Compose([            \n",
    " transforms.Resize(256),                   \n",
    " transforms.CenterCrop(224),              \n",
    " transforms.ToTensor(),                    \n",
    " transforms.Normalize(                     \n",
    " mean=[0.485, 0.456, 0.406],             \n",
    " std=[0.229, 0.224, 0.225]                  \n",
    " )])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading and setting up CIFAR-10 File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Getting datafile, creating directory\n",
    "datafile = CIFAR10(root='datafile/', download=True, transform=transform)\n",
    "test_datafile = CIFAR10(root='datafile/', train=False, transform=transform)\n",
    "\n",
    "#Getting 10 classes from the datafile\n",
    "classes = datafile.classes\n",
    "\n",
    "torch.manual_seed(43)\n",
    "valsize = 10000\n",
    "trainsize = len(datafile) - valsize\n",
    "\n",
    "trainds, valds = random_split(datafile, [trainsize, valsize])\n",
    "\n",
    "batchsize=100\n",
    "\n",
    "train_loader = DataLoader(trainds, batchsize, shuffle=False, num_workers=8, pin_memory=True)\n",
    "val_loader = DataLoader(valds, batchsize, num_workers=8, pin_memory=True)\n",
    "test_loader = DataLoader(test_datafile, batchsize, num_workers=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B of Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 )  moving van : 1065\n",
      "2 )  fox squirrel, eastern fox squirrel, Sciurus niger : 627\n",
      "3 )  sorrel : 331\n",
      "4 )  container ship, containership, container vessel : 285\n",
      "5 )  English foxhound : 259\n",
      "6 )  milk can : 232\n",
      "7 )  Japanese spaniel : 224\n",
      "8 )  thresher, thrasher, threshing machine : 224\n",
      "9 )  Dandie Dinmont, Dandie Dinmont terrier : 220\n",
      "10 )  chain saw, chainsaw : 171\n"
     ]
    }
   ],
   "source": [
    "#Getting 1000 classes from imagenet classes \n",
    "#Source: https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a \n",
    "with open(\"imagenet_classes.txt\") as f:\n",
    "    classes = eval(f.read())\n",
    "\n",
    "# Creating temp collections\n",
    "holder = []\n",
    "dic = {}\n",
    "current = ''\n",
    "\n",
    "#Iterating to batch of testloader and gets the output from alexnet\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        out = alexnet(images) \n",
    "\n",
    "\n",
    "        for j in range(0,batchsize):\n",
    "            sorted_out, indices = torch.sort(out,descending=True)\n",
    "            percentage = F.softmax(out,dim=1)[j]*100\n",
    "            results = [(classes[i.item()],percentage[i].item()) for i in indices[j][:5]]\n",
    "            holder.append(results[0][0])\n",
    "\n",
    "# Setting classification names\n",
    "holder.sort()\n",
    "\n",
    "#Getting the dictionary populated \n",
    "for z in holder:\n",
    "    if current != z:\n",
    "        count = 1\n",
    "        dic[z] = count\n",
    "        current = z\n",
    "    else:\n",
    "        count = count + 1\n",
    "        dic[z] = count \n",
    "        current = z\n",
    "        \n",
    "#sorting the dictionary \n",
    "sorteddictionary = dict( sorted(dic.items(), key=operator.itemgetter(1),reverse=True))\n",
    "\n",
    "#Printing top 10 classifications \n",
    "dicMax = 1\n",
    "for i in sorteddictionary:\n",
    "    print(dicMax,') ',i,':',sorteddictionary[i])\n",
    "    dicMax = dicMax + 1\n",
    "    if(dicMax > 10):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet   CCCV  CSC  DDDDT  EF  FESS  JS  MC  MV  SO  TTTM\n",
      "CIFAR-10                                                  \n",
      "AM           0    0      0   0     1   0   0   0   0     0\n",
      "AP           0    0      0   0     0   0   0   1   0     0\n",
      "B            0    0      0   0     0   0   0   0   1     0\n",
      "C            1    0      0   0     0   0   0   0   0     0\n",
      "DG           0    0      0   0     0   0   1   0   0     0\n",
      "DR           0    0      0   1     0   0   0   0   0     0\n",
      "FG           0    0      0   0     0   1   0   0   0     0\n",
      "H            0    0      0   0     0   0   0   0   0     1\n",
      "S            0    0      1   0     0   0   0   0   0     0\n",
      "T            0    1      0   0     0   0   0   0   0     0\n"
     ]
    }
   ],
   "source": [
    "#Short forms from CIFAR10\n",
    "cyactual = pd.Series(['AP','AM','B','C','DR','DG','FG','H','S','T'], name='CIFAR-10')\n",
    "\n",
    "#Short forms from above \n",
    "cypredicted = pd.Series(['MV','FESS','SO','CCCV','EF','MC','JS','TTTM','DDDDT','CSC'], name='AlexNet')\n",
    "dfconfusion = pd.crosstab(cyactual, cypredicted)\n",
    "\n",
    "#Printing matrix\n",
    "print(dfconfusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C of Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch[1/2] loss:0.7377: 100%|██████████████████████████████████████████████████| 400/400 [04:22<00:00,  1.52it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:12<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] training loss: 0.8946  value accuracy: 0.7297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch[2/2] loss:0.6900: 100%|██████████████████████████████████████████████████| 400/400 [04:17<00:00,  1.55it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:13<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 2] training loss: 0.7141  value accuracy: 0.7449\n",
      "Training Finished\n",
      "Starting to test with train partition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 400/400 [04:13<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 3.0364\n",
      "Start Testing with valadation partition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:12<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.7449\n",
      "Testing with Test Partition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:08<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing accuracy: 0.7454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = (\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "model = models.alexnet(pretrained=True)\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "b =[]\n",
    "for layer in model.classifier.children():\n",
    "    b.append(layer)\n",
    "b = b[:-5]\n",
    "\n",
    "b.append(nn.Linear(4096, 10))\n",
    "newclassifier = nn.Sequential(*b)\n",
    "model.classifier = newclassifier\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0002, momentum=0.9)\n",
    "save_path = './AlexNetc.pth'\n",
    "bestacc = 0.0\n",
    "train_steps = len(train_loader)\n",
    "epochs = 2\n",
    "\n",
    "#Start the training\n",
    "print(\"Starting Training\")\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    train_bar = tqdm(train_loader)\n",
    "    for i, data in enumerate(train_bar):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        train_bar.desc = \"Train epoch[{}/{}] loss:{:.4f}\".format(epoch + 1,\n",
    "                                                                     epochs,\n",
    "                                                                     loss)\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    acc = 0.0\n",
    "    with torch.no_grad():\n",
    "        val_bar = tqdm(val_loader)\n",
    "        for data in val_bar:\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            acc += torch.eq(predicted, labels).sum().item()\n",
    "    valaccurate = acc / valsize\n",
    "    print('[epoch %d] training loss: %.4f  value accuracy: %.4f' %\n",
    "              (epoch + 1, running_loss / train_steps, valaccurate))\n",
    "\n",
    "    if valaccurate > bestacc:\n",
    "        bestacc = valaccurate\n",
    "        torch.save(model.state_dict(), save_path)        \n",
    "print('Training Finished')\n",
    "\n",
    "#Starting testing with train partition \n",
    "print('Starting to test with train partition')\n",
    "model.load_state_dict(torch.load(save_path))\n",
    "model.eval()\n",
    "acc = 0.0\n",
    "with torch.no_grad():\n",
    "    test_bar = tqdm(train_loader)\n",
    "    for data in test_bar:\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        acc += torch.eq(predicted, labels).sum().item()\n",
    "testaccuracy = acc / 10000\n",
    "print('Testing accuracy: %.4f' %(testaccuracy))\n",
    "\n",
    "\n",
    "#Evaluating test partition \n",
    "print('Start Testing with valadation partition')\n",
    "model.load_state_dict(torch.load(save_path))\n",
    "model.eval()\n",
    "acc = 0.0\n",
    "with torch.no_grad():\n",
    "    test_bar = tqdm(val_loader)\n",
    "    for data in test_bar:\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        acc += torch.eq(predicted, labels).sum().item()\n",
    "testaccuracy = acc / 10000\n",
    "print('Testing Accuracy: %.4f' %(testaccuracy))\n",
    "\n",
    "\n",
    "#Test partition evalation \n",
    "print('Testing with Test Partition')\n",
    "model.load_state_dict(torch.load(save_path))\n",
    "model.eval()\n",
    "acc = 0.0\n",
    "with torch.no_grad():\n",
    "    test_bar = tqdm(test_loader)\n",
    "    for data in test_bar:\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        acc += torch.eq(predicted, labels).sum().item()\n",
    "testaccuracy = acc / 10000\n",
    "print('testing accuracy: %.4f' %(testaccuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part D of Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch[1/2] loss:16.4014: 100%|█████████████████████████████████████████████████| 400/400 [04:32<00:00,  1.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:16<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] Training Loss: 57.5335  Accuracy Value: 0.6836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch[2/2] loss:13.5730: 100%|█████████████████████████████████████████████████| 400/400 [04:33<00:00,  1.46it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:16<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 2] Training Loss: 32.0591  Accuracy Value: 0.7203\n",
      "Training Finished\n",
      "Testing with training partition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 400/400 [04:24<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracy: 2.9014\n",
      "Finished Training\n",
      "Start Testing with validation partition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:16<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.7203\n",
      "Testing with Testing Partition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:11<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.7183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "model = models.alexnet(pretrained=True)\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "b =[]\n",
    "for layer in model.classifier.children():\n",
    "    b.append(layer)\n",
    "b = b[:-2]\n",
    "\n",
    "b.append(nn.Linear(4096, 10))\n",
    "newclassifier = nn.Sequential(*b)\n",
    "model.classifier = newclassifier\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "save_path = './AlexNetc.pth'\n",
    "bestacc = 0.0\n",
    "train_steps = len(train_loader)\n",
    "epochs = 2\n",
    "\n",
    "print(\"Starting Training\")\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    train_bar = tqdm(train_loader)\n",
    "    for i, data in enumerate(train_bar):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        train_bar.desc = \"train epoch[{}/{}] loss:{:.4f}\".format(epoch + 1,\n",
    "                                                                     epochs,\n",
    "                                                                     loss)\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    acc = 0.0\n",
    "    with torch.no_grad():\n",
    "        val_bar = tqdm(val_loader)\n",
    "        for data in val_bar:\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            acc += torch.eq(predicted, labels).sum().item()\n",
    "    valaccurate = acc / valsize\n",
    "    print('[epoch %d] Training Loss: %.4f  Accuracy Value: %.4f' %\n",
    "              (epoch + 1, running_loss / train_steps, valaccurate))\n",
    "\n",
    "    if valaccurate > bestacc:\n",
    "        bestacc = valaccurate\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "\n",
    "            \n",
    "print('Training Finished')\n",
    "print('Testing with training partition')\n",
    "model.load_state_dict(torch.load(save_path))\n",
    "model.eval()\n",
    "acc = 0.0\n",
    "with torch.no_grad():\n",
    "    test_bar = tqdm(train_loader)\n",
    "    for data in test_bar:\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        acc += torch.eq(predicted, labels).sum().item()\n",
    "testaccuracy = acc / 10000\n",
    "print('test_accuracy: %.4f' %(testaccuracy))\n",
    "\n",
    "\n",
    "print('Finished Training')\n",
    "print('Start Testing with validation partition')\n",
    "model.load_state_dict(torch.load(save_path))\n",
    "model.eval()\n",
    "acc = 0.0\n",
    "with torch.no_grad():\n",
    "    test_bar = tqdm(val_loader)\n",
    "    for data in test_bar:\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        acc += torch.eq(predicted, labels).sum().item()\n",
    "testaccuracy = acc / 10000\n",
    "print('Testing Accuracy: %.4f' %(testaccuracy))\n",
    "\n",
    "\n",
    "print('Testing with Testing Partition')\n",
    "model.load_state_dict(torch.load(save_path))\n",
    "model.eval()\n",
    "acc = 0.0\n",
    "with torch.no_grad():\n",
    "    test_bar = tqdm(test_loader)\n",
    "    for data in test_bar:\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        acc += torch.eq(predicted, labels).sum().item()\n",
    "testaccuracy = acc / 10000\n",
    "print('Testing Accuracy: %.4f' %(testaccuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
